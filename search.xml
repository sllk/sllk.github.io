<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>FTB中fallThroughErr逻辑梳理</title>
      <link href="/2025/09/02/FTB%E4%B8%ADfallThroughErr%E9%80%BB%E8%BE%91%E6%A2%B3%E7%90%86/"/>
      <url>/2025/09/02/FTB%E4%B8%ADfallThroughErr%E9%80%BB%E8%BE%91%E6%A2%B3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="FTB中fallThroughErr逻辑梳理"><a href="#FTB中fallThroughErr逻辑梳理" class="headerlink" title="FTB中fallThroughErr逻辑梳理"></a>FTB中fallThroughErr逻辑梳理</h1><ol><li><strong>FTB Bank读取阶段断言检查</strong></li></ol><ul><li>在读取FTB条目时，验证预测的fallThrough地址是否超出范围（必须保证指令块的结束地址不超过预测范围）</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Check if the entry read by ftbBank is legal.</span></span><br><span class="line"><span class="keyword">for</span> (n &lt;- <span class="number">0</span> to numWays - <span class="number">1</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> req_pc_reg       = <span class="type">RegEnable</span>(io.req_pc.bits, <span class="number">0.</span><span class="type">U</span>.asTypeOf(io.req_pc.bits), io.req_pc.valid)</span><br><span class="line">  <span class="keyword">val</span> req_pc_reg_lower = <span class="type">Cat</span>(<span class="number">0.</span><span class="type">U</span>(<span class="number">1.</span><span class="type">W</span>), req_pc_reg(instOffsetBits + log2Ceil(<span class="type">PredictWidth</span>) - <span class="number">1</span>, instOffsetBits))</span><br><span class="line">  <span class="keyword">val</span> ftbEntryEndLowerwithCarry = <span class="type">Cat</span>(read_entries(n).carry, read_entries(n).pftAddr)</span><br><span class="line">  <span class="keyword">val</span> fallThroughErr            = req_pc_reg_lower + <span class="type">PredictWidth</span>.<span class="type">U</span> &gt;= ftbEntryEndLowerwithCarry</span><br><span class="line">  when(read_entries(n).valid &amp;&amp; total_hits(n) &amp;&amp; io.s1_fire) &#123;</span><br><span class="line">    assert(fallThroughErr, <span class="string">s&quot;FTB read sram entry in way<span class="subst">$&#123;n&#125;</span> fallThrough address error!&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>流水线S2阶段的地址校验</strong></li></ol><ul><li>检查起始地址（startLower）是否大于等于结束地址（endLowerwithCarry）</li><li>或者结束地址是否超出预测块范围（startLower + PredictWidth）</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> real_s2_startLower        = <span class="type">Cat</span>(<span class="number">0.</span><span class="type">U</span>(<span class="number">1.</span><span class="type">W</span>), real_s2_pc(instOffsetBits + log2Ceil(<span class="type">PredictWidth</span>) - <span class="number">1</span>, instOffsetBits))</span><br><span class="line"><span class="keyword">val</span> real_s2_endLowerwithCarry = <span class="type">Cat</span>(real_s2_ftb_entry.carry, real_s2_ftb_entry.pftAddr)</span><br><span class="line"><span class="keyword">val</span> real_s2_fallThroughErr =</span><br><span class="line">  real_s2_startLower &gt;= real_s2_endLowerwithCarry || real_s2_endLowerwithCarry &gt; (real_s2_startLower + <span class="type">PredictWidth</span>.<span class="type">U</span>)</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>流水线S3阶段的最终校验</strong></li></ol><ul><li>校验地址</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> fallThroughErr =</span><br><span class="line">    s3_pc_startLower &gt;= s3_ftb_entry_endLowerwithCarry || s3_ftb_entry_endLowerwithCarry &gt; (s3_pc_startLower + <span class="type">PredictWidth</span>.<span class="type">U</span>)</span><br><span class="line">  <span class="type">XSError</span>(</span><br><span class="line">    s3_ftb_entry_dup(<span class="number">0</span>).valid &amp;&amp; s3_hit_dup(<span class="number">0</span>) &amp;&amp; io.s3_fire(<span class="number">0</span>) &amp;&amp; fallThroughErr,</span><br><span class="line">    <span class="string">&quot;FTB read sram entry in s3 fallThrough address error!&quot;</span></span><br><span class="line">  )</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>FTB更新写入校验</strong></li></ol><ul><li>在更新FTB时校验写入地址</li></ul><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> ftb_write_fallThrough = ftb_write.entry.getFallThrough(write_pc)</span><br><span class="line">  when(write_valid) &#123;</span><br><span class="line">    assert(write_pc + (<span class="type">FetchWidth</span> * <span class="number">4</span>).<span class="type">U</span> &gt;= ftb_write_fallThrough, <span class="string">s&quot;FTB write_entry fallThrough address error!&quot;</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>超标量处理器设计_Virtual_Memory</title>
      <link href="/2025/09/02/2_Virtual_Memory/"/>
      <url>/2025/09/02/2_Virtual_Memory/</url>
      
        <content type="html"><![CDATA[<h1 id="超标量处理器笔记-虚拟存储器"><a href="#超标量处理器笔记-虚拟存储器" class="headerlink" title="超标量处理器笔记_虚拟存储器"></a>超标量处理器笔记_虚拟存储器</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h2><p>现代的高性能处理器都支持虚拟地址Virtual address但是为什么需要虚拟地址。</p><p>随着应用程序规模越来越大，以至于物理内存已经无法容纳下这样的程序了，通常的做法就是把程序分割成很多片段，片段0首先放到物理内存中执行，当他执行完时调用下一个片段。</p><p>虽然片段在物理内存中的交换是操作系统完成的，但是程序眼需要先对程序进行分割，费时费力。</p><p>为了解决这个问题，有了虚拟存储器Virtual Memory。</p><p>虚拟存储器的基本思想，是对于一个程序来说，它的程序code数据data和堆栈stack的总大小可以超过实际物理内存的大小，操作系统把当前使用的部分放到物理内存中，而把其他未使用的内容放到下一级存储器，如硬盘或闪存。这样不需要进行分割。</p><p>有了这一样的概念就可以说一个程序是运行在虚拟存储器空间的，空间大小由处理器的位数决定。</p><blockquote><p>[!TIP]</p><p>对于一个32位的处理器来说，其地址范围就是0~0xFFFF_FFFF,也就是4GB,这个范围就是处理器能够产生的地址范围。</p></blockquote><p>其中的某一个地址就称为虚拟地址，与虚拟存储器相对应的就是物理存储器，其中的某一个地址就是物理地址。物理存储器的大小不能超过处理器最大可以寻址的空间</p><hr><p>在没有使用虚拟地址的系统中，处理器输出的地址会直接送到物理存储器中，如图所示。</p><img src="/2025/09/02/2_Virtual_Memory/image-20250902183833552.png" alt="image-20250902183833552" style="zoom:80%;"><p>如果使用了虚拟地址，则虚地址不会被直接送到物理存储器中，而是需要先进行地址转换，负责地址转换的部件一般称为<strong>内存管理单元Memory Manage Unit(MMU)</strong></p><img src="/2025/09/02/2_Virtual_Memory/image-20250902184117499.png" alt="image-20250902184117499" style="zoom:80%;"><p>使用虚拟存储器之后，每个程序总认为它占有处理器的所有地址空间，因此程序可以任意使用处理器的地址资源，这样在编写程序的时候，不需要考虑地址的限制，每个程序都认为处理器中只有自己在运行。当这些程序真正放到处理器中运行时，由操作系统负责调度，讲物理存储器动态分配给各个程序。将每个程序的虚拟地址转化为物理地址。</p><p>通过操作系统转化可以实现程序保护，即使两个程序都使用了同一个虚拟地址，他们也会对应到不同物理地址，因此可以保证每个程序的内容不会被其他程序随便改写。</p><p>这种方式还可以实现程序间的共享。</p><blockquote><p>[!TIP]</p><p>例如程序A,B都使用了printf函数，操作系统在进行地址转换的时候，会将地址A,B转化为同样的物理地址，这个地址就是printf函数的物理地址</p></blockquote><p>因此虚拟存储器不仅可以降低物理存储器的容量需求，还可以带来其他好处，如保护和共享。</p><hr><h2 id="地址转换"><a href="#地址转换" class="headerlink" title="地址转换"></a>地址转换</h2><p>虚拟存储器目前最通用的方式是<strong>基于分页(page)的虚拟存储器</strong>,虚拟地址空间的划分以页为单位，典型页大小为4KB，相应的物理地址空间也进行同样大小的划分。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Xiangshan_BPU_FTB</title>
      <link href="/2025/09/02/2_FTB/"/>
      <url>/2025/09/02/2_FTB/</url>
      
        <content type="html"><![CDATA[<h1 id="Xiangshan-BPU-FTB"><a href="#Xiangshan-BPU-FTB" class="headerlink" title="Xiangshan_BPU_FTB"></a>Xiangshan_BPU_FTB</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>FTB 是香山 BPU 的第三个子预测器，它也能一并获取到 uFTB 和 TAGE-SC 的输出。在 FTB 的输入接口中，s1 通道含有 uFTB 的基础预测结果，s2 通道和 s3 通道中仅有 br_taken_mask 一组信号被 TAGE-SC 填充，并无 FTB 项生成的基础预测结果。FTB 的工作便是为 s2 和 s3 通道提供基础预测结果。</p><p>FTB 在功能和结构上都与 uFTB 类似，其主要区别就是 FTB 能够容纳更多的 FTB 项，并且 FTB 的预测结果是在 s2 与 s3 通道输出。正是由于容量大，其读出的速度上会比 uFTB 慢，无法被放置在第一周期产生预测结果，但大容量也使它能够获得更加精准的预测结果。</p><h2 id="功能概述"><a href="#功能概述" class="headerlink" title="功能概述"></a>功能概述</h2><ul><li><p>缓存更多 FTB 项，为 s2 和 s3 通道提供基础预测结果。 FTB 预测器的本质是一个较大容量的存储器，其会根据当前预测的 PC 读出对应的 FTB 项，并在 s2 阶段产出预测结果。与此同时该 FTB 项还会被再保存一个周期，生成 s3 阶段预测结果。</p></li><li><p>根据更新请求，更新存储中的 FTB 项。</p></li></ul><img src="/2025/09/02/2_FTB/image-20250902104522023.png" alt="image-20250902104522023" style="zoom:80%;"><h3 id="接收请求"><a href="#接收请求" class="headerlink" title="接收请求"></a>接收请求</h3><ol><li>S0阶段时，FTB向内部FTBbank发送读请求，其请求pc值为S0传入的PC.</li><li>发送请求的下一拍 S1，暂存从FTB SRAM读出的多路信号。</li><li>S2从暂存数据中根据各路tag和实际请求时tag匹配情况生成命中信号并在命中时选出命中的FTB数据，若存在hit请求，则返回值为选出的 FTB 项及命中的路信息。</li></ol><p>FTBBank 模块读出的数据在FTB模块内作为 2 阶段的预测结果以组合逻辑连线形式在当拍传递给后续预 测器，此外这一读出的结果还会被暂存到 FTB 模块内，在 3 阶段作为预测结果再次以组合逻辑连线传递给后续 预测器。若 FTB 命中，则读出的命中路编号也会作为 meta 信息在 s3 与命中信息、周期数一起传递给后续 FTQ 模块。</p><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>收到update请求后，FTB会根据meta中的hit信息来决定更新时间，若meta中为hit，则本拍更新，否则要延迟两周期等待读出FTB内现有结果后更新。</p><p>在FTBBank内部，当存在更新请求时，该模块行为也因立即更新和推迟更新两情况而有所不同。立即更新时，FTBBank内的 SRAM写通道拉高，按照给定的信息完成写入。</p><p>推迟更新时，FTBbank首先收到一个update的读请求，下一拍读出数据，选出给定地址命中的路编码传递给外部FTB模块，而若这一拍未命中，则下一拍需要写入到分配的路中。路选取规则为，若所有路均已写满，则使用替换算法。</p><h3 id="SRAM规格"><a href="#SRAM规格" class="headerlink" title="SRAM规格"></a>SRAM规格</h3><p><strong>单bank，512set，4way，使用单口SRAM，无读保持，有上电复位。 20bit tag，60bit FTB项。</strong></p><h2 id="FTB存储结构"><a href="#FTB存储结构" class="headerlink" title="FTB存储结构"></a>FTB存储结构</h2><p>FTB项</p><table><thead><tr><th>total</th><th>valid</th><th>brSlot</th><th>tailSlot</th><th>pftAddr</th><th>carry</th><th>isCall, isRet, isJalr</th><th></th><th></th></tr></thead><tbody><tr><td></td><td>有效位</td><td>第一条分支信息</td><td>第二条分支信息</td><td>预测块结束地址</td><td>结束地址高位是否进位</td><td>tailSlot分支类型</td><td>RAS标识特殊位</td><td>强 bias</td></tr><tr><td>62</td><td>1</td><td>21</td><td>29</td><td>4</td><td>1</td><td>3</td><td>1</td><td>2</td></tr></tbody></table><p>FTB slot</p><table><thead><tr><th>total</th><th>valid</th><th>offset</th><th>lower</th><th>tarStat</th><th>sharing</th><th>isRVC</th></tr></thead><tbody><tr><td></td><td>有效位</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>21&#x2F;29</td><td>1</td><td>4</td><td>12&#x2F;20</td><td>2</td><td>1</td><td>1</td></tr></tbody></table><h2 id="目标地址生成逻辑"><a href="#目标地址生成逻辑" class="headerlink" title="目标地址生成逻辑"></a>目标地址生成逻辑</h2><p>对于每个slot，根据三种可能的高位进位情况（进位&#x2F;退位&#x2F;不变），在（PC高位+1, PC高位‑1, PC高位）三种情况中选择一个，和存储的目标地址低位信息进行拼位</p><h2 id="更新流程"><a href="#更新流程" class="headerlink" title="更新流程"></a>更新流程</h2><ol><li><p>表项生成</p><ul><li>从FTQ读信息startAddr,old_entry,包含FTQ项内32Byte内所有分支指令的预译码信息pd,此FTQ项内有效指令的真实跳转结果 cfiIndex，包括是否跳转，以及跳转指令相对startAddr的偏移,此FTQ项内分支指令（如跳转）的跳转地址（执行结果）,预测时FTB是否真正命中（旧FTB项是否有效），对应 FTQ 项内所有可能指令的误预测 mask</li></ul></li><li><p>写入流程</p><p>2.1 写入条件：新FTB项完全没有变化，或者虽然FTB未命中但uFTB命中：不需写入;新FTB项有变化且非uFTB命中、FTB未命中的情况：需要写入</p></li></ol><p>写入SRAM的流水线示意图</p><p><img src="/2025/09/02/2_FTB/image-20250902111441931.png" alt="image-20250902111441931"></p><h2 id="Chisel代码分析"><a href="#Chisel代码分析" class="headerlink" title="Chisel代码分析"></a>Chisel代码分析</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">FTBParams</span> <span class="keyword">extends</span> <span class="title">HasXSParameter</span> <span class="keyword">with</span> <span class="title">HasBPUConst</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> numEntries = <span class="type">FtbSize</span><span class="comment">//FtbSize: Int = 2048</span></span><br><span class="line">  <span class="keyword">val</span> numWays    = <span class="type">FtbWays</span><span class="comment">//FtbWays: Int = 4,</span></span><br><span class="line">  <span class="keyword">val</span> numSets    = numEntries / numWays <span class="comment">// 512</span></span><br><span class="line">  <span class="keyword">val</span> tagLength  = <span class="type">FtbTagLength</span><span class="comment">//FtbTagLength: Int = 20,</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TAR_STAT_SZ</span> = <span class="number">2</span><span class="comment">//定义状态字段的位宽为2位</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">TAR_FIT</span>     </span>= <span class="number">0.</span><span class="type">U</span>(<span class="type">TAR_STAT_SZ</span>.<span class="type">W</span>)<span class="comment">//00: 地址匹配状态（Target Address FIT）</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">TAR_OVF</span>     </span>= <span class="number">1.</span><span class="type">U</span>(<span class="type">TAR_STAT_SZ</span>.<span class="type">W</span>)<span class="comment">//01: 地址溢出状态（Target Address Overflow）</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">TAR_UDF</span>     </span>= <span class="number">2.</span><span class="type">U</span>(<span class="type">TAR_STAT_SZ</span>.<span class="type">W</span>)<span class="comment">//10: 地址下溢状态（Target Address Underflow）</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">BR_OFFSET_LEN</span>  </span>= <span class="number">12</span><span class="comment">//分支指令偏移量位宽</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">JMP_OFFSET_LEN</span> </span>= <span class="number">20</span><span class="comment">//跳转指令偏移量位宽</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">FTBCLOSE_THRESHOLD_SZ</span> </span>= log2Ceil(<span class="number">500</span>)<span class="comment">// 阈值计数器位宽</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">FTBCLOSE_THRESHOLD</span>    </span>= <span class="number">500.</span><span class="type">U</span>(<span class="type">FTBCLOSE_THRESHOLD_SZ</span>.<span class="type">W</span>) <span class="comment">// can be modified 阈值常量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这些常量用于表示目标地址预测的状态：</p><ol><li><strong>TAR_FIT</strong>：表示预测地址与实际地址匹配（无偏移）</li><li><strong>TAR_OVF</strong>：表示预测地址过高（需要+1调整）</li><li><strong>TAR_UDF</strong>：表示预测地址过低（需要-1调整）</li></ol><p>在硬件实现中：</p><ul><li>使用2位宽度存储状态值</li><li>通过Mux1H多路复用器根据状态选择对应的目标地址计算方式</li><li>这些状态会影响后续的地址生成逻辑，例如在FTBEntry类的getTarget方法中会根据这些状态调整地址高位部分</li></ul><ol><li><strong>BR_OFFSET_LEN (12位)</strong><br>用于分支指令的偏移量字段长度，决定分支目标地址低位部分的存储精度。例如：<ul><li>支持的最大分支偏移量为 2^12 &#x3D; 4096</li></ul></li><li><strong>JMP_OFFSET_LEN (20位)</strong><br>用于跳转指令的偏移量字段长度，比分支指令需要更大范围：<ul><li>支持的最大跳转偏移量为 2^20 &#x3D; 1MB</li><li>更长的偏移量允许存储更大范围的跳转目标地址</li></ul></li><li><strong>FTBCLOSE_THRESHOLD (500)</strong><ul><li>用于控制FTB（分支目标缓冲区）关闭机制的阈值</li><li>当某个计数器达到500时，触发FTB请求关闭逻辑</li><li>使用log2Ceil(500)计算得到9位宽度（因为2^8&#x3D;256 &lt; 500 &lt; 512&#x3D;2^9）</li></ul></li></ol><hr><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FtbSlot_FtqMem</span>(<span class="params">implicit p: <span class="type">Parameters</span></span>) <span class="keyword">extends</span> <span class="title">XSBundle</span> <span class="keyword">with</span> <span class="title">FTBParams</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> offset  = <span class="type">UInt</span>(log2Ceil(<span class="type">PredictWidth</span>).<span class="type">W</span>)<span class="comment">//指令偏移量字段</span></span><br><span class="line">  <span class="keyword">val</span> sharing = <span class="type">Bool</span>()<span class="comment">//共享标志</span></span><br><span class="line">  <span class="keyword">val</span> valid   = <span class="type">Bool</span>()<span class="comment">//有效性标志</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><strong>offset</strong> 字段<ul><li>位宽：log2Ceil(PredictWidth) 位</li><li>用途：存储指令在预测块中的偏移位置</li><li>示例：当 PredictWidth&#x3D;8（每周期预测8条指令）时，offset为3位（0~7）</li><li>在FTB中用于定位分支指令在指令块中的精确位置</li></ul></li><li><strong>sharing</strong> 字段<ul><li>布尔类型</li><li>用途：指示该槽位是否与其他槽位共享信息</li><li>典型场景：<ul><li>当多个分支共享相同的目标地址时，可通过该标志实现空间优化</li><li>用于区分独立分支和共享分支的存储方式</li></ul></li></ul></li><li><strong>valid</strong> 字段<ul><li>布尔类型</li><li>用途：表示该槽位是否包含有效的预测信息</li><li>作用：<ul><li>控制预测结果的有效性</li><li>用于槽位分配和替换策略</li><li>在预测过程中过滤无效的预测条目</li></ul></li></ul></li></ol><hr><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FtbSlot</span>(<span class="params">val offsetLen: <span class="type">Int</span>, val subOffsetLen: <span class="type">Option</span>[<span class="type">Int</span>] = <span class="type">None</span></span>)(<span class="params">implicit p: <span class="type">Parameters</span></span>) <span class="keyword">extends</span> <span class="title">FtbSlot_FtqMem</span></span></span><br><span class="line">    <span class="keyword">with</span> <span class="type">FTBParams</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (subOffsetLen.isDefined) &#123;</span><br><span class="line">    require(subOffsetLen.get &lt;= offsetLen)<span class="comment">// 要求子偏移量必须小于等于offsetLen</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> lower   = <span class="type">UInt</span>(offsetLen.<span class="type">W</span>)</span><br><span class="line">  <span class="keyword">val</span> tarStat = <span class="type">UInt</span>(<span class="type">TAR_STAT_SZ</span>.<span class="type">W</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setLowerStatByTarget</span></span>(pc: <span class="type">UInt</span>, target: <span class="type">UInt</span>, isShare: <span class="type">Boolean</span>) = &#123;<span class="comment">// 根据高位地址比较结果生成状态</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTargetStatByHigher</span></span>(pc_higher: <span class="type">UInt</span>, target_higher: <span class="type">UInt</span>) =</span><br><span class="line">      <span class="type">Mux</span>(target_higher &gt; pc_higher, <span class="type">TAR_OVF</span>, <span class="type">Mux</span>(target_higher &lt; pc_higher, <span class="type">TAR_UDF</span>, <span class="type">TAR_FIT</span>))<span class="comment">// 目标地址超过PC范围 -&gt; 溢出;目标地址不足/匹配 -&gt; 下溢/适配</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLowerByTarget</span></span>(target: <span class="type">UInt</span>, offsetLen: <span class="type">Int</span>) = target(offsetLen, <span class="number">1</span>)<span class="comment">// 从目标地址提取低位部分（用于缓存索引）;取[offsetLen:1]位（忽略最低位，因通常对齐访问）</span></span><br><span class="line">    <span class="keyword">val</span> offLen        = <span class="keyword">if</span> (isShare) <span class="keyword">this</span>.subOffsetLen.get <span class="keyword">else</span> <span class="keyword">this</span>.offsetLen<span class="comment">// 根据共享标志选择偏移长度</span></span><br><span class="line">    <span class="keyword">val</span> pc_higher     = pc(<span class="type">VAddrBits</span> - <span class="number">1</span>, offLen + <span class="number">1</span>)<span class="comment">// 提取高位地址段（用于范围比较）</span></span><br><span class="line">    <span class="keyword">val</span> target_higher = target(<span class="type">VAddrBits</span> - <span class="number">1</span>, offLen + <span class="number">1</span>)<span class="comment">// 目标地址高位段</span></span><br><span class="line">    <span class="keyword">val</span> stat          = getTargetStatByHigher(pc_higher, target_higher)<span class="comment">// 生成地址比较状态 进位or not</span></span><br><span class="line">    <span class="keyword">val</span> lower         = <span class="type">ZeroExt</span>(getLowerByTarget(target, offLen), <span class="keyword">this</span>.offsetLen)<span class="comment">// 提取低位并零扩展到标准位宽</span></span><br><span class="line">    <span class="comment">// 更新模块内部状态寄存器</span></span><br><span class="line">    <span class="keyword">this</span>.lower   := lower<span class="comment">// 存储计算出的低位地址</span></span><br><span class="line">    <span class="keyword">this</span>.tarStat := stat<span class="comment">// 存储地址比较状态</span></span><br><span class="line">    <span class="keyword">this</span>.sharing := isShare.<span class="type">B</span><span class="comment">// 存储共享模式标志</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getTarget</span></span>(pc: <span class="type">UInt</span>, last_stage: <span class="type">Option</span>[<span class="type">Tuple2</span>[<span class="type">UInt</span>, <span class="type">Bool</span>]] = <span class="type">None</span>) = &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTarget</span></span>(offLen: <span class="type">Int</span>)(pc: <span class="type">UInt</span>, lower: <span class="type">UInt</span>, stat: <span class="type">UInt</span>, last_stage: <span class="type">Option</span>[<span class="type">Tuple2</span>[<span class="type">UInt</span>, <span class="type">Bool</span>]] = <span class="type">None</span>) = &#123;</span><br><span class="line">      <span class="keyword">val</span> h                = pc(<span class="type">VAddrBits</span> - <span class="number">1</span>, offLen + <span class="number">1</span>)</span><br><span class="line">      <span class="keyword">val</span> higher           = <span class="type">Wire</span>(<span class="type">UInt</span>((<span class="type">VAddrBits</span> - offLen - <span class="number">1</span>).<span class="type">W</span>))</span><br><span class="line">      <span class="keyword">val</span> higher_plus_one  = <span class="type">Wire</span>(<span class="type">UInt</span>((<span class="type">VAddrBits</span> - offLen - <span class="number">1</span>).<span class="type">W</span>))</span><br><span class="line">      <span class="keyword">val</span> higher_minus_one = <span class="type">Wire</span>(<span class="type">UInt</span>((<span class="type">VAddrBits</span> - offLen - <span class="number">1</span>).<span class="type">W</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Switch between previous stage pc and current stage pc</span></span><br><span class="line">      <span class="comment">// Give flexibility for timing</span></span><br><span class="line">      <span class="keyword">if</span> (last_stage.isDefined) &#123;</span><br><span class="line">        <span class="keyword">val</span> last_stage_pc   = last_stage.get._1</span><br><span class="line">        <span class="keyword">val</span> last_stage_pc_h = last_stage_pc(<span class="type">VAddrBits</span> - <span class="number">1</span>, offLen + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">val</span> stage_en        = last_stage.get._2</span><br><span class="line">        higher           := <span class="type">RegEnable</span>(last_stage_pc_h, stage_en)</span><br><span class="line">        higher_plus_one  := <span class="type">RegEnable</span>(last_stage_pc_h + <span class="number">1.</span><span class="type">U</span>, stage_en)</span><br><span class="line">        higher_minus_one := <span class="type">RegEnable</span>(last_stage_pc_h - <span class="number">1.</span><span class="type">U</span>, stage_en)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        higher           := h</span><br><span class="line">        higher_plus_one  := h + <span class="number">1.</span><span class="type">U</span></span><br><span class="line">        higher_minus_one := h - <span class="number">1.</span><span class="type">U</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> target =</span><br><span class="line">        <span class="type">Cat</span>(</span><br><span class="line">          <span class="type">Mux1H</span>(<span class="type">Seq</span>(</span><br><span class="line">            (stat === <span class="type">TAR_OVF</span>, higher_plus_one),</span><br><span class="line">            (stat === <span class="type">TAR_UDF</span>, higher_minus_one),</span><br><span class="line">            (stat === <span class="type">TAR_FIT</span>, higher)</span><br><span class="line">          )),</span><br><span class="line">          lower(offLen - <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">          <span class="number">0.</span><span class="type">U</span>(<span class="number">1.</span><span class="type">W</span>)</span><br><span class="line">        )</span><br><span class="line">      require(target.getWidth == <span class="type">VAddrBits</span>)</span><br><span class="line">      require(offLen != <span class="number">0</span>)</span><br><span class="line">      target</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (subOffsetLen.isDefined)</span><br><span class="line">      <span class="type">Mux</span>(</span><br><span class="line">        sharing,</span><br><span class="line">        getTarget(subOffsetLen.get)(pc, lower, tarStat, last_stage),</span><br><span class="line">        getTarget(offsetLen)(pc, lower, tarStat, last_stage)</span><br><span class="line">      )</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      getTarget(offsetLen)(pc, lower, tarStat, last_stage)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fromAnotherSlot</span></span>(that: <span class="type">FtbSlot</span>) = &#123;</span><br><span class="line">    require(</span><br><span class="line">      <span class="keyword">this</span>.offsetLen &gt; that.offsetLen &amp;&amp; <span class="keyword">this</span>.subOffsetLen.map(_ == that.offsetLen).getOrElse(<span class="literal">true</span>) ||</span><br><span class="line">        <span class="keyword">this</span>.offsetLen == that.offsetLen</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">this</span>.offset  := that.offset</span><br><span class="line">    <span class="keyword">this</span>.tarStat := that.tarStat</span><br><span class="line">    <span class="keyword">this</span>.sharing := (<span class="keyword">this</span>.offsetLen &gt; that.offsetLen &amp;&amp; that.offsetLen == <span class="keyword">this</span>.subOffsetLen.get).<span class="type">B</span></span><br><span class="line">    <span class="keyword">this</span>.valid   := that.valid</span><br><span class="line">    <span class="keyword">this</span>.lower   := <span class="type">ZeroExt</span>(that.lower, <span class="keyword">this</span>.offsetLen)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">slotConsistent</span></span>(that: <span class="type">FtbSlot</span>) =</span><br><span class="line">    <span class="type">VecInit</span>(</span><br><span class="line">      <span class="keyword">this</span>.offset === that.offset,</span><br><span class="line">      <span class="keyword">this</span>.lower === that.lower,</span><br><span class="line">      <span class="keyword">this</span>.tarStat === that.tarStat,</span><br><span class="line">      <span class="keyword">this</span>.sharing === that.sharing,</span><br><span class="line">      <span class="keyword">this</span>.valid === that.valid</span><br><span class="line">    ).reduce(_ &amp;&amp; _)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>超标量处理器设计_Cache</title>
      <link href="/2025/09/01/1_cache/"/>
      <url>/2025/09/01/1_cache/</url>
      
        <content type="html"><![CDATA[<h1 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h1><p>L1 Cache L2 Cache</p><p>l1c快，每个核私有的。l2c全，可能是核之间共享的（现代也可能是l3c共享）</p><p>ICache:需要每周期能读多条指令，延迟时间即使很大，也不会造成处理器性能下降</p><p>DCache:需要支持每周期有多条load store指令访问，需要多端口设计</p><h3 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h3><p>cache主要由两部分组成，Tag部分和Data部分，一个Tag和它对应的所有数据组成的一行称为一个<code>Cache line</code>,数据部分</p><p>称为数据块Cache data block&#x2F;Cache block&#x2F;Data block,若一个数据可以存储在擦车中的多个地方，则这些被同一地址找到的多个Cache Line称为Cache Set。</p><h3 id="Cache的实现方式"><a href="#Cache的实现方式" class="headerlink" title="Cache的实现方式"></a>Cache的实现方式</h3><ol><li><p>直接映射 direct-mapped Cache</p><p>对物理内存中的一个数据来说，如果Cache中只有一个地方可以容纳它，则为直接映射。</p></li><li><p>组相联set-associative Cache</p><p>如果Cache中有多个地方可以放置这个数据，则为组相联。</p></li><li><p>全相联fully-associative Cache</p><p>如果Cache中任何一个地方都可以放置这个数据，则为全相联。</p></li></ol><blockquote><p>[!NOTE]</p><p>TLB的Victim Cache多采用全相联，而普通的I-Cache和D-Cache采用组相联</p></blockquote><p><img src="/2025/09/01/1_cache/image-20250828093051829.png" alt="image-20250828093051829"></p><h3 id="Cache的缺失"><a href="#Cache的缺失" class="headerlink" title="Cache的缺失"></a>Cache的缺失</h3><p>Cache容量有限,只能保存近期处理器使用过的内容，并且很多情况下要找的指令或数据不在Cache中，即为Cache缺失 Cache miss：</p><ol><li><p>Compulsory</p><p>Cache只是缓存以前访问过的内容，故第一次被访问的指令&#x2F;数据不在Cache中，不过可以采取预取(prefetching)的方法来降低这种缺失发生率。</p></li><li><p>Capcity </p><p>容量造成Cache缺失发生率。</p></li><li><p>Conflict</p><p>多个数据映射到Cache中同一个位置的情况导致的缺失，可以使用Victim Cache来解决。</p></li></ol><p>这三种影响Cache缺失的条件又叫3C定理。</p><h2 id="1-Cache的一般设计"><a href="#1-Cache的一般设计" class="headerlink" title="1.Cache的一般设计"></a>1.Cache的一般设计</h2><h3 id="Cache组成方式"><a href="#Cache组成方式" class="headerlink" title="Cache组成方式"></a>Cache组成方式</h3><h4 id="直接映射"><a href="#直接映射" class="headerlink" title="直接映射"></a>直接映射</h4><p>最容易实现，处理器访问地址存储器地址被分为三个部分：</p><table><thead><tr><th>Tag</th><th>Index</th><th>Block Offset</th></tr></thead></table><ul><li>Index来从Cache中找到一个对应的Cache line。</li><li>但是所有Index相同的地址都会寻址到这个Cache line，因此需要Tag来和地址中的Tag进行比较，只有当他们相等时，才说明这个Cache line正确。</li><li>在一个Cache line中有很多数据，通过Block Offset部分可以找到需要的数据。</li><li>Cache line中还有一个有效位Valid，只有在之前被访问过的存储器地址，数据才会存在于对应Cache line中，相应的，有效位也会被置1。</li></ul><p><img src="/2025/09/01/1_cache/image-20250828093111007.png" alt="image-20250828093111007"></p><blockquote><p>[!NOTE]</p><p>直接映射结构实现上是最简单的，不需要替换算法，但效率最低</p></blockquote><h4 id="组相联"><a href="#组相联" class="headerlink" title="组相联"></a>组相联</h4><p>为了解决直接相联结构Cache不足而提出的, 存储器中的一个数据可以放在多个Cache line中</p><blockquote><p>[!NOTE]</p><p>对应一个组相联结构的Cache来说，如果一个数据可以放在n个位置，则为n路组相联</p></blockquote><p><img src="/2025/09/01/1_cache/image-20250828093125415.png" alt="image-20250828093125415"></p><ul><li>index部分对Cache进行寻址，可以获得x个Cache line（设x为组相联数）， 然后通过Tag对比来确定结果</li></ul><p>如果index索引到的所有cache line，都与tag不匹配，则为Cache缺失</p><p>因为要从多个Cache line中选择，所以相比直接映射，延迟更大(有时需要用到流水线)，但是可以显著减少Cache确实的概率</p><p>这种结构是使用最广泛的</p><p>组相联的Tag和Data是分开存放的，分别为Tag SRAM和Data SRAM，可以同时访问</p><ul><li>并行访问Tag和Data:</li><li>串行访问Tag和Data：先访问Tag后访问Data</li></ul><blockquote><p>[!NOTE]</p><p>一般将选择字节的过程称为数据对齐</p></blockquote><p><img src="/2025/09/01/1_cache/image-20250828192438625.png" alt="image-20250828192438625"></p><p>Cache访问一般都是处理器中的关键路径，图中这个结构实现了单周期的访问操作，延时很长，组要对Cache访问进行流水线划分：</p><ul><li>指令Cache进行流水线对性能不影响，仍可实现每周期读取指令</li><li>但数据Cache如果进行流水线切分就会增加Load指令的延迟</li></ul><p>下图是并行访问的流水线结构，通过这种方式可以降低处理器周期实践。</p><p><img src="/2025/09/01/1_cache/image-20250828192531378.png" alt="image-20250828192531378"></p><p>而对于串行访问，可以先访问Tag SRAM，这样就可以先知道数据部分中哪一路数据是需要访问的，就不需要Way Mux多路选择器了 ，但是这样就增加了一个周期，会增加load指令的延迟</p><p><img src="/2025/09/01/1_cache/image-20250828192644541.png" alt="image-20250828192644541"></p><p>两种方式各有优劣</p><p>并行访问时会有较低的时钟频率和较大的功耗，但是cache访问缩短了一个周期</p><p>在超标量处理器中，当Cache的访问处于关键路径上时，可以使用串行访问来提高时钟频率</p><p>在普通处理器中，无法对指令进行调度，因此如果增加一个周期，就很可能会导致处理器性能的降低，因此使用并行</p><h4 id="全相联"><a href="#全相联" class="headerlink" title="全相联"></a>全相联</h4><p>一个存储器地址对应的数据可以放置在任意一个Cache line中，存储器地址中没有index部分，而是直接在Cache中进行Tag比较，找到比较结果相等的那个Cache line。相当于直接使用存储器内容来寻址。</p><blockquote><p>[!NOTE]</p><p>这就是内容寻址的存储器，CAM</p></blockquote><p>实际处理器在使用全相联结构的Cache时都是使用CAM来存储Tag值，使用普通RAM来存储数据的，在CAM中某一行被寻址到后，SRAM中对应的行也将会被找到。</p><p>全相联结构有着最大的灵活度，因此缺失率是最低的，但是延迟最大。</p><h3 id="Cache写入"><a href="#Cache写入" class="headerlink" title="Cache写入"></a>Cache写入</h3><blockquote><p>[!NOTE]</p><p>自修改self-modifying：将要改写的指令作为数据写入到D-Cache中，然后将D-Cache中的内容写到下级存储器中（例如L2，必须是指令和数据Cache共享的）并将I-Cache中所有指令置为无效，如此处理器再次执行时，就会使用被修改的指令了。</p></blockquote><h4 id="写回与写通"><a href="#写回与写通" class="headerlink" title="写回与写通"></a>写回与写通</h4><p>在执行store指令时，如果只是向D-Cache中写入数据，并不改变它对应的下级存储器中的数据，那么就会导致D-Cache和它对应的下级存储器中的数据不一致(non-consistent),要解决这个问题，有写通和写回两种方法</p><ul><li>写通</li></ul><p>​数据在写入到D-Cache的同时，也写到它的下级存储器中</p><p>​但是下级存储器的访问实践通常较长，而且store指令出现的频率高，因此处理器执行效率不高。</p><ul><li>写回</li></ul><p>​数据写入到D-Cache的同时，不写入到下级存储器，而是对写入的Cache line做一个记号(dirty)，在当前Cache line被替换时，才将它写入到下级存储器中。</p><p>​这样会减少写慢速存储器的频率，但是会给存储器一致性管理来负担。</p><h4 id="写缺失"><a href="#写缺失" class="headerlink" title="写缺失"></a>写缺失</h4><p>当对Cache写入时，发现这个地址不在Cache中，这就发生了<strong>写缺失</strong></p><p>写缺失的解决方法包括Non-Write-Allocate，Write Allocate</p><ul><li>Non-Write-Allocate</li></ul><p>​直接将数据写入到下级存储器中，而不是写入到D-Cache中</p><ul><li>Write Allocate</li></ul><p>​在发生缺失时，会首先从下级存储器中将这个发生缺失的地址对应的整个数据块取出来，将要写入到D-Cache中的数据合并到这个数据块中，然后再将这个被修改过的数据块写到D-Cache中。</p><blockquote><p>[!NOTE]</p><p>在发生写缺失时，为什么不直接从D-Cache中找到一个line，将要写入的信息直接写到这个line中，同时也将它写到下级寄存器中呢？为啥还要先从下级存储器中将对应数据块读出来并写到D-Cache中？</p></blockquote><p>因为在处理器中，写入D-Cache最多写入一个字，如果直接从D-Cache中找到一个line来存储这个需要写入的数据并将这个line标记为dirty状态，，会导致这个line中，数据块中的其他部分和下级存储器中对应地址数据不一致，而此时D-Cache中这些数据是无效的，如果这个cache line由于被替换而写回到下级存储器中时，就会使下级存储器中的正确数据被篡改。<strong>（这个地方看的不是很明白）</strong></p><ul><li>对D-Cache来说，一般情况下，<strong>写通</strong>要配合Non_Write Allocate一起使用，都是直接将数据更新到下级存储器中，如下图。</li></ul><p><img src="/2025/09/01/1_cache/image-20250829204357686.png" alt="image-20250829204357686"></p><ul><li>同样<strong>写回</strong>和Write Allocate也是配合在一起的</li></ul><p><img src="/2025/09/01/1_cache/image-20250830103915892.png" alt="image-20250830103915892"></p><h3 id="Cache-替换策略"><a href="#Cache-替换策略" class="headerlink" title="Cache 替换策略"></a>Cache 替换策略</h3><ol><li>近期最少使用法(Least Recently Used,LRU)</li></ol><p>​选择最近被使用次数最少的Cache line，这需要为每个Cache line都设置一个年龄age，每次当一个一个Cache line被访问时，它的年龄部分就会增加，（或其他Cache line的年龄值减少）， 这样在进行替换时，年龄最小的那个Cache line就是被使用次数最少的。</p><p>​举个例子，一个两路组相联结构，每个way就只需要一位age就可以吗，当一个way被使用时，这个way的年龄被置1，另一个way的年龄部分被置零。 但随着Cache相关度的增加，即way个数的增加，要实现这种LRU算法就很昂贵了，因此在相关度很高的cache中，都是使用<strong>伪LRU算法</strong>， 将所有way进行分组，每一组使用一个1位的年龄部分。</p><p>​<img src="/2025/09/01/1_cache/image-20250830145824667.png" alt="image-20250830145824667"></p><ol><li>随机替换</li></ol><p>​Cache的替换算法一般是使用硬件来实现的， 因此如果做的很复杂，会影响处理器的周期时间，于是就有了随即替换。</p><p>​这种方法不需要记录每个way的年龄信息，而是随机选择一个way进行替换。相比LRU，这种方法发生缺失的频率会更高，但随着Cache容量增大，这个差距越来越小。</p><p>​不过在现实中很难实现严格的随机，一般采用一种时钟算法(clock algorithm)的方法来实现近似的随机。</p><h2 id="2-提高Cache的性能"><a href="#2-提高Cache的性能" class="headerlink" title="2.提高Cache的性能"></a>2.提高Cache的性能</h2><p>采用更复杂的方法来提高Cache的性能，包括<strong>写缓存</strong>、<strong>流水线</strong>、<strong>多级结构</strong>、<strong>Victim Cache</strong>、和<strong>预取</strong>等</p><p>在超标量处理器中，还有其他方法来提高Cache性能，如非阻塞Cache、关键字优先和提前开始等。</p><h3 id="写缓存"><a href="#写缓存" class="headerlink" title="写缓存"></a>写缓存</h3><p>​当D-Cache发生缺失时，需要从下一级存储器中读取数据写入到一个选定的Cache line中，如果这个line是脏的状态，需要先把这个line中的数据写回到下级存储器中，然后才能读取下级存储器而得到缺失的数据，而下级存储器的访问时间都比较长，这种串行的过程导致D-Cache发生缺失的处理时间变得很长，因此可以使用写缓存write buffer</p><p>​脏状态的Cache line会首先放到写缓存中，等到下级存储器有空闲的时候，才会将写缓存中的数据写到下级存储器中。</p><p><img src="/2025/09/01/1_cache/image-20250830154442048.png" alt="image-20250830154442048"></p><p>​对于写回类型的D-Cache来说，当一个脏状态的Cache line被替换时，这个line的数据会首先放到写缓存中，然后就可以从下级存储器中读数据了，而写缓存中的数据会择机写入到下级存储器中。</p><p>​对于写通类型来说，采用写缓存后，每当数据写道D-Cache的同时，并不会同时也写到下级存储器中，而是将其放到写缓存中。</p><blockquote><p>[!IMPORTANT]</p><p>写通类型Cache由于便于进行存储器一致性的管理，所以在多核处理器中，L1 Cache会经常采用这种结构。</p><p>写缓存对写通类型的Cache尤为重要。</p></blockquote><blockquote><p>[!WARNING]</p><p>加入写缓存后，会增加系统设计的复杂度，例如当读取D-Cache发生缺失时，不仅需要从下级存储器中查找这个数据，还需要在写缓存中也查找。</p></blockquote><hr><h3 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h3><p>对于读D-Cache来说，由于Tag SRAM和Data SRAM可以在同时进行读取，所以在处理器的周期不是很严格的时候，可以在一个周期完成读写操作。</p><p>但对于写D-Cache来说，读取Tag SRAM和Data SRAM操作只能串行完成，在主频高的处理器中，这些操作很难一个周期内完成，这就需要对D-Cache写操作采用流水线结构。</p><p>流水线划分方式有很多种，典型的就是将Tag SRAM的读取和比较放在一个周期，写Data SRAM放在下一个周期。</p><p><img src="/2025/09/01/1_cache/image-20250830164331104.png" alt="image-20250830164331104"></p><p>在这种机制中，load指令在D-Cache命中的情况下，可以在一个周期内完成，store指令两周期。</p><p>需要注意的是，当执行load指令时，它要的数据可能正好在store指令的流水线寄存器中，而不是来自Data SRAM，因此需要一种机制，能够检测到这种情况。这需要将load指令所携带的地址和store指令的流水线寄存器进行比较，如果相等，则将store指令的数据作为load指令的结果。</p><h3 id="多级结构"><a href="#多级结构" class="headerlink" title="多级结构"></a>多级结构</h3><p>​存储器无法实现容量大同时速度又很快，所以使用多级结构来使处理器看起来使用了一个容量大同时速度快的存储器。</p><p><img src="/2025/09/01/1_cache/image-20250901092440322.png" alt="image-20250901092440322"></p><p>L1 Cache容量很小，能够跟处理器内核保持同样的速度等级，L2 Cache访问通常需要几个时钟周期，但容量大一些。一些高阶的处理器还会有片上的L3 Cache。</p><p>在一般处理器中L2 Cache会使用写回方式，但对于L1 Cache来说，写通实现方式也是可以接受的。</p><p>对于多级结构Cache，需要了解两个概念，Inclusive和Exclusive：</p><ul><li>Inclusive：如果L2 Cache 包括了L1 Cache中所有的内容，则称L2 Cache是Inclusive的。</li><li>Exclusive：如果L2 Cache和L1 Cache中的内容互不相同，则L2 Cache是Exclusive的</li></ul><p><img src="/2025/09/01/1_cache/image-20250901093349660.png" alt="image-20250901093349660"></p><p>Inclusive是比较浪费硬件资源的，因为将一份数据保存在两个地方。但是好处是可以直接将数据写道L1 Cache中，虽然此时L1中的数据被覆盖，但是L2中存在这个数据的备份，但被覆盖的line不能是dirty的。</p><p>并且Inclusive也简化了一致性管理。</p><blockquote><p>[!NOTE]</p><p>现代的大多数处理器都采用了Inclusive类型的Cache。</p></blockquote><hr><h3 id="Victim-Cache"><a href="#Victim-Cache" class="headerlink" title="Victim Cache"></a>Victim Cache</h3><p>​有时候Cache中被踢出的数据可能马上又要被使用，例如在一个2 way的cache中，有三个频繁使用的数据位于同一个cache set中。这样需要频繁的踢出-写入。cache始终无法命中数据。</p><p>​</p><p><img src="/2025/09/01/1_cache/image-20250901094613341.png" alt="image-20250901094613341"></p><p>VC可以存储最近被踢出Cache的数据，通常VC采用全相联方式，容量都比较小 4~16个。</p><img src="/2025/09/01/1_cache/1_Cache\image-20250901094849815.png" alt="image-20250901094849815" style="zoom:80%;"><p>VC本质上相当于增加Cache中way的个数，降低Cache的缺失率。</p><p>一般情况下，Cache和VC存在互斥关系，不会包含同样的数据，处理器内核可以同时读取，如果在Cache中没有找到想要的数据但在VC中找到了，跟Cache命中效果是一样的，同时VC的数据被写到cache中，cache中被替换的数据写到VC中。</p><blockquote><p>[!NOTE]</p><p>现代大多数处理器都采用了VC</p></blockquote><p>还有一种类似的设计思路称为Filter Cache。当一个数据第一次被使用时，它不会马上被放到cache中，等到这个数据再次被使用时，才会被搬移到cache。这样可以防止偶然被使用的数据占据Cache。</p><h3 id="预取"><a href="#预取" class="headerlink" title="预取"></a>预取</h3><p>当处理器第一次访问一条指令或数据时，这个指令或数据肯定不会在cache中。可以采取预取来缓解这个问题。</p><ol><li>硬件预取</li></ol><p>​对于指令来说，猜测后续会执行什么指令是相对容易的，因为程序是串行执行的，只需要在访问ICache中的一个数据块的时候，将它后面的数据块也去出来放到ICache就可以了。</p><p>​但程序中可能存在分支指令，所以这种猜测也可能出错，使不被使用的指令进入了ICache，这样不光降低了Cache的可用容量，还占用了本来可能有用的指令，这称为“<strong>Cache 污染</strong>”</p><img src="/2025/09/01/1_cache/1_Cache\image-20250901102315555.png" alt="image-20250901102315555" style="zoom:80%;"><p>​硬件预取如图所示，当ICache发生缺失时，除了将需要的数据块从L2中取出来放到L1中，还会将下一个数据块也取出来，放到Stream Buffer中。</p><p>​如果在ICache中发生了缺失，但是在Stream Buffer中找到了想要的指令，这时除了使用Stream Buffer中读取的指令外，还会将其中对应的数据块搬移到ICache中，同时继续从L2中取下一个数据块放到Stream Buffer中。</p><p>​这样当程序中没有分支指令时，会一直正常工作，并降低Cache缺失率，但遇到分支指令会导致Stream Buffer中的数据无效。</p><blockquote><p>[!NOTE]</p><p>对于DCache来说，顾虑更加难以捕捉，一般当访问DCache发生缺失时，除了将所需的数据块从下级存储器中取出来之外，还需要将下一个数据块也读取出来。</p></blockquote><ol start="2"><li>软件预取</li></ol><p>​在程序编译阶段，编译器就可以对程序进行分析，从而知道哪些数据需要进行预取。如果在指令集中设有预取指令，则编译器就可以直接控制程序进行预取。</p><blockquote><p>[!NOTE]</p><p>软件预取有一个前提，就是预取时机，如果预取太晚，则需要的时候还没有取出来，预取就没意义。如果太早就可能踢掉DCache中一些本来有用的数据，造成污染。</p></blockquote><p>​使用软件预取指令时，处理器要能够继续指令，也就是继续从DCache中读取数据，这就<strong>要求DCache时非阻塞结构的</strong>。</p><p>在是西安虚拟存储器Virtual Memory的系统中，预取指令可能会引起一些异常，如发生Page Fault,虚拟地址错误或者保护违例等。</p><p>有两种处理方式：</p><ul><li>处理错误的预取指令</li><li>不处理错误的预取指令，此时发生异常的预取指令就会变成一条空指令</li></ul><hr><h2 id="3-多端口Cache"><a href="#3-多端口Cache" class="headerlink" title="3.多端口Cache"></a>3.多端口Cache</h2><p>​在超标量处理器中，为提高性能，处理器需要能在每周期同时执行多条load&#x2F;store指令，这需要一个多端口的DCache。</p><blockquote><p>[!NOTE]</p><p>在超标量处理器中，有很多部件都是多端口结构：寄存器堆，发射队列，重排序缓存等。但这些部件容量不大，所以及时采用多端口结构，也不会对芯片面积和速度产生太大负面影响。</p></blockquote><p>但Dcache容量很大，因此需要采用一些方法来解决这个问题：</p><h3 id="True-Mulit-port"><a href="#True-Mulit-port" class="headerlink" title="True Mulit-port"></a>True Mulit-port</h3><p><strong>在现实当中不可能对Cache直接采用多端口的设计。</strong></p><p>​这种方法真的使用一个多端口的SRAM来实现多端口的Cache。以双端口为例，所有的Cache中的控制通路和数据通路都要进行复制，这就表示他有两套地址解码器Address Decoder，两个多路选择器Way Mux，比较器数量也增加一倍，并且要有两个对齐器。</p><h3 id="Mulitple-Cache-Copies"><a href="#Mulitple-Cache-Copies" class="headerlink" title="Mulitple Cache Copies"></a>Mulitple Cache Copies</h3><p>这种方法将Tag SRAM和Data SRAM进行复制，如图所示。</p><p>这种方式和上一种本质上时是一样的，但是通过将Cache复制，SRAM不需要再使用多端口结构，几乎可以消除对处理器周期的影响，但是浪费了很多的面积。而且需要保持两个Cache之间的同步。</p><p><img src="/2025/09/01/1_cache/image-20250901143746563.png" alt="image-20250901143746563"></p><h3 id="Multi-banking"><a href="#Multi-banking" class="headerlink" title="Multi-banking"></a>Multi-banking</h3><p>将cache分为很多小的bank，每个bank都只有一个端口。</p><blockquote><p>[!NOTE]</p><p>这种方式是现实中处理器最广泛使用的方法</p></blockquote><p>如果在一个周期之内，若Cache的多个端口上的访问地址位于不同bank之中，则不会有任何问题。</p><p>只有当两个或者多个端口的地址位于同一个bank之中，才会引起冲突bank conflict。</p><p>使用这种方法，一个双端口的Cache仍旧需要两个地址解码器，两个多路选择器，两套比较器和两个对齐器，而<strong>Data SRAM就不需要多端口结构了</strong>。这样提高了速度而且在一定程度上节省了面积。</p><p>但由于需要判断Cache的每个端口是不是命中，所以对于Tag SRAM来说，仍需要提供多个端口同时读取的功能，也就是采用多端口SRAM来实现，或者采用将但端口SRAM进行复制的方法。</p><p>如图所示，只有在两个端口都访问一个bank时，才会产生冲突，在当前周期只能对一个端口进行响应。</p><p><img src="/2025/09/01/1_cache/image-20250901145538679.png" alt="image-20250901145538679"></p><blockquote><p>[!TIP]</p><p>影响多端口Cache性能的一个关键因素就是bank冲突，可以采用更多的bank来缓解这个问题，使bank冲突发生概率尽可能降低。</p></blockquote><h2 id="4-超标量处理器的取指令"><a href="#4-超标量处理器的取指令" class="headerlink" title="4.超标量处理器的取指令"></a>4.超标量处理器的取指令</h2><p>如果一个超标量处理器每周期可以同时解码四条指令，这个处理器就称为4-way的超标量处理器。</p><blockquote><p>[!IMPORTANT]</p><p>对于一个n-way的超标量处理器来说，它给出一个取指令的地址后，I-Cache应能够至少送出n条指令，称这n条指令为一组(fetch group)</p></blockquote><p>ICache如何能实现这个功能，最简单的方法使使数据块的大小为n个子，每周期全部输出</p><p><img src="/2025/09/01/1_cache/image-20250901152830225-1756713662483-31.png" alt="image-20250901152830225"></p><p>如图所示，如果处理器送出的取指令地址使n字对齐的，就可以实现每周期从ICache中读取n条指令的功能，在数据块部分需要n个32位的SRAM，当I-Cache命中时，这些SRAM会同时进行输出，不过这是理想的情况，实际情况下由于存在跳转指令，处理器送出的取指令地址不可能是n字对齐的</p><p><img src="/2025/09/01/1_cache/image-20250901163146948.png" alt="image-20250901163146948"></p><p>如下图所示，取指令的地址不是四字对齐，一个组中的指令就可能落在两个Cache line中，但对于Cache来说，每周期只能够访问一个Cache line，这会导致在一个周期内无法取出四条指令。图中这种情况就只能取出三条指令。这就会导致后续的流水线无法得到充足的指令，使部分资源空置。</p><p>假设在取指令的组中第一条指令位置是随机的，每周期能够取出的指令个数是：<br>$$<br>\frac{1}{4} \times 4 + \frac{1}{4} \times 3 + \frac{1}{4} \times 2 + \frac{1}{4} \times 1 &#x3D; 2.5<br>$$<br><img src="/2025/09/01/1_cache/image-20250901175551689.png" alt="image-20250901175551689"></p><p>这对于4way的超标量处理器是不够的，但是对于2way的处理器来说，就够用了。</p><p>这种分析是悲观的，在实际应用中每周期平均可以取出多于2.5条的指令，因为即使当前周期送出的取指令地址不是四字对齐的，下个周期取指令的地址也会变成四字对齐。</p><blockquote><p>[!CAUTION]</p><p>指令组中第一条指令位于数据块中第一个字的概率是要大于在其他位置的概率。</p></blockquote><p><img src="/2025/09/01/1_cache/image-20250901184953995.png" alt="image-20250901184953995"></p><p>即使取指令的地址没有四字对齐，也有一些方法能够在一周期内读取四条指令。</p><p>最简单的就是使数据块变大，比如增大到8个，只要取指令地址不是落在最后三个字上，就可以在每个周期内读取4条指令。</p><p>但这种方法也有问题，在Cache容量一定的情况下，这种方法使Cache set的数量减少，会增加Cache的缺失率，因此不一定使性能提升。</p><p><img src="/2025/09/01/1_cache/image-20250901190714489.png" alt="image-20250901190714489"></p><blockquote><p>[!WARNING]</p><p>如果每个数据块大小是八个字，也就需要使用八个32位的SRAM来实现这个Cache。在实际版图设计中，每块SRAM周围都需要摆放一圈保护电路，若SRAM个数过多，会使保护电路占用过多面积。而且要从八个字中选出四个字也是浪费亮度，需要大量布线资源和多路选择器，故<strong>在实际当中仍会使用四个SRAM来实现一个大小位八个字的数据块</strong>。</p></blockquote><p><img src="/2025/09/01/1_cache/image-20250901192802501.png" alt="image-20250901192802501"></p><p>如上图所示的Cache中，一个Cache line占用的八个字实际上占据了SRAM的两行，因此共使用了四个32位的SRAM。每次Cache命中时，每个SRAM的两行数据都是有效的。</p><p>但需要注意，这时候四个SRAM的输出并不是按照指令原始顺序进行排列的，例如图中SRAM0就应在最后，因此需要一段重排序的逻辑电路对四个SRAM的指令进行重排序。</p><p>这种结构的Cache需要两个额外的控制电路：</p><ol><li>产生每个SRAM的都地址</li><li>将四个SRAM输出的内容进行重排序，重排序逻辑电路如图</li></ol><p><img src="/2025/09/01/1_cache/image-20250901194149174.png" alt="image-20250901194149174"></p><blockquote><p>[!NOTE]</p><p>如果取指地址指向了Cache line中的后三个字，此时本周期不能输出四条指令，所以在重排序逻辑电路中还需要加入指示每条指令是否有效的标志信号</p></blockquote><p>如果在处理器中有分支预测功能，则上述取指令的过程还需要更复杂一些</p><p><img src="/2025/09/01/1_cache/image-20250901194759477.png" alt="image-20250901194759477"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
